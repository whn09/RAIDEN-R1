# SGLang å¿«é€Ÿéƒ¨ç½²æŒ‡å—

## ğŸ“‹ å‰ç½®æ¡ä»¶

âœ… p5en.48xlarge å®ä¾‹ (8x H100 80GB)
âœ… CUDA å’Œ nvidia-smi å¯ç”¨
âœ… Python 3.8+

## ğŸš€ ä¸€é”®éƒ¨ç½²

### æ­¥éª¤ 1: ä¸‹è½½æ¨¡å‹ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰

æ¨èæ¨¡å‹ä¸‹è½½æ¥æºï¼š
- HuggingFace
- ModelScope
- æœ¬åœ°æ¨¡å‹ä»“åº“

```bash
# ç¤ºä¾‹ï¼šä¸‹è½½ GLM-4 (9B)
# é€‰æ‹©åˆé€‚çš„ä¸‹è½½æ–¹å¼
```

### æ­¥éª¤ 2: éƒ¨ç½² SGLang

```bash
# æ–¹æ³• 1: ä½¿ç”¨è„šæœ¬ï¼ˆæ¨èï¼‰
./scripts/deploy_sglang.sh \
    --model-path /path/to/your/model \
    --model-name your-model-name \
    --tp-size 8

# æ–¹æ³• 2: æ‰‹åŠ¨å¯åŠ¨
python -m sglang.launch_server \
    --model-path /path/to/your/model \
    --host 0.0.0.0 \
    --port 30000 \
    --tp-size 8 \
    --mem-fraction-static 0.9
```

**æ¨èé…ç½®**:

| æ¨¡å‹ | TP Size | ç«¯å£ | å‘½ä»¤ |
|------|---------|------|------|
| MiniMax M2 | 8 | 30000 | `--tp-size 8` |
| GLM-4 (9B) | 4 | 30000 | `--tp-size 4` |
| Qwen2.5-14B | 4 | 30000 | `--tp-size 4` |
| Qwen2.5-32B | 8 | 30000 | `--tp-size 8` |

### æ­¥éª¤ 3: éªŒè¯éƒ¨ç½²

```bash
# æ£€æŸ¥å¥åº·çŠ¶æ€
curl http://localhost:30000/health

# æµ‹è¯•æ¨ç†
curl -X POST http://localhost:30000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "your-model",
    "messages": [{"role": "user", "content": "ä½ å¥½"}],
    "max_tokens": 50
  }'
```

### æ­¥éª¤ 4: ç”Ÿæˆæ•°æ®

```bash
# å¿«é€Ÿæµ‹è¯•
python scripts/test_sglang_generator.py

# ç”Ÿæˆæ•°æ®
python scripts/generate_data_with_sglang.py \
    --profiles_file ./data/online_profiles.jsonl \
    --num_samples_per_profile 2 \
    --include_cm
```

## ğŸ“Š æ€§èƒ½é¢„æœŸ

### p5en.48xlarge (8x H100)

| æ¨¡å‹ | tokens/ç§’ | æ ·æœ¬/å°æ—¶ | 1000æ ·æœ¬æ—¶é—´ |
|------|-----------|-----------|--------------|
| MiniMax M2 (TP=8) | ~2000 | ~800 | 10-15åˆ†é’Ÿ |
| GLM-4 (TP=4) | ~4000 | ~1600 | 5-8åˆ†é’Ÿ |
| Qwen2.5-14B (TP=4) | ~2500 | ~1000 | 8-12åˆ†é’Ÿ |

## ğŸ”§ å¸¸è§é—®é¢˜

### 1. æ¨¡å‹åŠ è½½å¤±è´¥
```bash
# æ£€æŸ¥æ¨¡å‹è·¯å¾„
ls -la /path/to/model

# æ£€æŸ¥ GPU å†…å­˜
nvidia-smi

# å‡å°‘ TP size
./scripts/deploy_sglang.sh --tp-size 4
```

### 2. OOM (æ˜¾å­˜ä¸è¶³)
```bash
# å‡å°‘å†…å­˜å ç”¨
./scripts/deploy_sglang.sh --memory-fraction 0.8

# ä½¿ç”¨æ›´å°çš„æ¨¡å‹
./scripts/deploy_sglang.sh --model-path /models/glm-4-9b-chat
```

### 3. ç”Ÿæˆé€Ÿåº¦æ…¢
```bash
# å¢åŠ  TP size
./scripts/deploy_sglang.sh --tp-size 8

# ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹
./scripts/deploy_sglang.sh --model-path /models/glm-4-9b-chat
```

## ğŸ“ å¿«é€Ÿå‘½ä»¤å‚è€ƒ

```bash
# éƒ¨ç½²
./scripts/deploy_sglang.sh --model-path MODEL_PATH --tp-size 8

# æµ‹è¯•
python scripts/test_sglang_generator.py

# ç”Ÿæˆ
python scripts/generate_data_with_sglang.py

# åœæ­¢
kill $(cat sglang_server_info.json | jq -r .pid)

# æŸ¥çœ‹æ—¥å¿—
tail -f logs/sglang_*.log

# ç›‘æ§ GPU
watch -n 1 nvidia-smi
```

## ğŸ¯ æ¨èå·¥ä½œæµ

1. **å¿«é€ŸéªŒè¯** (10ä¸ªè§’è‰²):
   ```bash
   ./scripts/deploy_sglang.sh --model-path MODEL_PATH --tp-size 4
   python scripts/generate_data_with_sglang.py --max_profiles 10
   ```

2. **å®Œæ•´ç”Ÿæˆ** (æ‰€æœ‰è§’è‰²):
   ```bash
   ./scripts/deploy_sglang.sh --model-path MODEL_PATH --tp-size 8
   python scripts/generate_data_with_sglang.py --include_cm
   ```

3. **æ‰¹é‡å¹¶è¡Œ** (å¤šä¸ªæœåŠ¡å™¨):
   ```bash
   # GPU 0-3
   CUDA_VISIBLE_DEVICES=0,1,2,3 ./scripts/deploy_sglang.sh \
       --model-path MODEL1 --port 30000

   # GPU 4-7
   CUDA_VISIBLE_DEVICES=4,5,6,7 ./scripts/deploy_sglang.sh \
       --model-path MODEL2 --port 30001
   ```

## ğŸ“– æ›´å¤šæ–‡æ¡£

- [è¯¦ç»†å¿«é€Ÿå¼€å§‹æŒ‡å—](SGLANG_QUICKSTART.md)
- [ä¸ Bedrock å¯¹æ¯”](GENERATION_COMPARISON.md)
- [å®Œæ•´æ•°æ®ç”Ÿæˆæ–‡æ¡£](DATA_GENERATION_GUIDE.md)

---

**å…³é”®ä¼˜åŠ¿**: æ¯” Bedrock å¿« 10-100 å€ï¼Œé›¶ API æˆæœ¬ï¼ ğŸš€
